apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: proc-ades
  namespace: proc
spec:
  chart:
    spec:
      chart: ades
      version: 2.0.0
      sourceRef:
        kind: HelmRepository
        name: eoepca
        namespace: common
  values:
    # values - start
    replicaCount: 1
    image:
      pullPolicy: Always
      # Overrides the image tag whose default is the chart appVersion.
      # tag: "2.0.3"
    nameOverride: ""
    fullnameOverride: ""
    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # Annotations to add to the service account
      annotations: {}
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""
    podAnnotations: {}
    podSecurityContext:
      {}
      # fsGroup: 2000
    securityContext:
      {}
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true
      # runAsUser: 1000
    service:
      type: ClusterIP
      port: 80
    ingress:
      enabled: true
      annotations: {}
      hosts:
        - host: ades-open.develop.eoepca.org
          paths:
            - path: /
              pathType: ImplementationSpecific    
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local
    resources:
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 2Gi
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 3
      targetCPUUtilizationPercentage: 80
      # targetMemoryUtilizationPercentage: 80
    storageClassName: managed-nfs-storage
    clusterAdminRoleName: cluster-admin
    nodeSelector: {}
    tolerations: []
    affinity: {}
    useKubeProxy: True
    workflowExecutor:
      # Necessary if useKubeProxy set to false
      # kubeconfig: "files/kubeconfig"

      # Here specify fixed inputs to all workflows execution in all stages (main, stage-in/out)
      # They will be prefixed with 'ADES_'. e.g. 'APP: ades' will be 'ADES_APP: ades'
      inputs:
        APP: ades

        STAGEIN_AWS_SERVICEURL: http://data.cloudferro.com
        STAGEIN_AWS_ACCESS_KEY_ID: test
        STAGEIN_AWS_SECRET_ACCESS_KEY: test

        STAGEOUT_AWS_SERVICEURL: https://cf2.cloudferro.com:8080
      #  STAGEOUT_AWS_ACCESS_KEY_ID: 4ceda7292edc4cc997d133079b469900
      #  STAGEOUT_AWS_SECRET_ACCESS_KEY: 7d824cbfc90147318fa6ac7fe0e9a174
      #  STAGEOUT_AWS_REGION: RegionOne
      #  STAGEOUT_OUTPUT: s3://processing_results

      #    STAGEOUT_STORAGE_HOST: https://nx13206.your-storageshare.de/
      #    STAGEOUT_STORAGE_USERNAME: eoepca-storagecd 
      #    STAGEOUT_STORAGE_APIKEY: 4k8wMajA5ABaYdk

      useResourceManager: "true"
      resourceManagerWorkspacePrefix: "develop-user"
      resourceManagerEndpoint: "https://workspace-api.develop.eoepca.org"
      platformDomain: "https://auth.develop.eoepca.org"

      pod_env_vars:
        yaml: "{}"


      # kubernetes storage class to be used for provisioning volumes. Must be a persistent volume claim compliant (glusterfs-storage)
      processingStorageClass: managed-nfs-storage
      # Size of the Kubernetes Tmp Volumes
      processingVolumeTmpSize: "6Gi"
      # Size of the Kubernetes Output Volumes
      processingVolumeOutputSize: "6Gi"
      # Max ram to use for a job
      processingMaxRam: "8Gi"
      # Max number of CPU cores to use concurrently for a job
      processingMaxCores: "4"
      # if false the Ades will clean the volume after the workflow has successfully finished running
      processingKeepWorkspace: "False"
      processingKeepWorkspaceIfFailed: "False"
      # image pull secrects
      imagePullSecrets: []
      #  custom stagein cwl
      #stageincwl: "files/stageincwl.cwl"
      #maincwl: "files/maincwlmetrics.cwl"

      main:
        cwl: |
          class: Workflow
          doc: Main stage manager
          id: main
          label: macro-cwl
          inputs: {}
          outputs:
            StacCatalogUri:
              outputSource:
                - node_stage_out/s3_catalog_output
              type: string  
          requirements:
            SubworkflowFeatureRequirement: {}
            ScatterFeatureRequirement: {}
          steps:
            node_stage_out:
              in: {}
              out: [s3_catalog_output]
              run: ''      

      stagein:
        cwl: |
          cwlVersion: v1.0
          baseCommand: Stars
          doc: "Run Stars for staging input data"
          class: CommandLineTool
          hints:
            DockerRequirement:
              dockerPull: terradue/stars:1.0.0-beta.11
          id: stars
          arguments:
          - copy
          - -v
          - -rel
          - -r
          - '4'
          - -o
          - ./
          - --harvest
          inputs:
            ADES_STAGEIN_AWS_SERVICEURL:
              type: string?
            ADES_STAGEIN_AWS_ACCESS_KEY_ID:
              type: string?
            ADES_STAGEIN_AWS_SECRET_ACCESS_KEY:
              type: string?
          outputs: {}
          requirements:
            EnvVarRequirement:
              envDef:
                PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
                # AWS__Profile: $(inputs.aws_profile)
                # AWS__ProfilesLocation: $(inputs.aws_profiles_location.path)
                AWS__ServiceURL: $(inputs.ADES_STAGEIN_AWS_SERVICEURL)
                AWS_ACCESS_KEY_ID: $(inputs.ADES_STAGEIN_AWS_ACCESS_KEY_ID)
                AWS_SECRET_ACCESS_KEY: $(inputs.ADES_STAGEIN_AWS_SECRET_ACCESS_KEY)
            ResourceRequirement: {}

      stageout:
        cwl: |
          cwlVersion: v1.0
          baseCommand: Stars
          doc: "Run Stars for staging results"
          class: CommandLineTool
          hints:
            DockerRequirement:
              dockerPull: terradue/stars:1.0.0-beta.11
          id: stars
          arguments:
            - copy
            - -v
            - -r
            - '4'
            - -o
            - $( inputs.ADES_STAGEOUT_OUTPUT + "/" + inputs.process )
            - -res
            - $( inputs.process + ".res" )
            - valueFrom: |
                ${
                    if( !Array.isArray(inputs.wf_outputs) )
                    {
                        return inputs.wf_outputs.path + "/catalog.json";
                    }
                    var args=[];
                    for (var i = 0; i < inputs.wf_outputs.length; i++)
                    {
                        args.push(inputs.wf_outputs[i].path + "/catalog.json");
                    }
                    return args;
                }
          inputs:
            ADES_STAGEOUT_AWS_PROFILE:
              type: string?
            ADES_STAGEOUT_AWS_SERVICEURL:
              type: string?
            ADES_STAGEOUT_AWS_ACCESS_KEY_ID:
              type: string?
            ADES_STAGEOUT_AWS_SECRET_ACCESS_KEY:
              type: string?
            aws_profiles_location:
              type: File?
            ADES_STAGEOUT_OUTPUT:
              type: string?
            ADES_STAGEOUT_AWS_REGION:
              type: string?
            process:
              type: string?
          outputs:
            s3_catalog_output:
              outputBinding:
                outputEval: ${  return inputs.ADES_STAGEOUT_OUTPUT + "/" + inputs.process + "/catalog.json"; }
              type: string
          requirements:
            InlineJavascriptRequirement: {}
            EnvVarRequirement:
              envDef:
                PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
                AWS__ServiceURL: $(inputs.ADES_STAGEOUT_AWS_SERVICEURL)
                AWS__SignatureVersion: "2"
                AWS_ACCESS_KEY_ID: $(inputs.ADES_STAGEOUT_AWS_ACCESS_KEY_ID)
                AWS_SECRET_ACCESS_KEY: $(inputs.ADES_STAGEOUT_AWS_SECRET_ACCESS_KEY)
                # uncomment if you need the S3 region
                #AWS__Region: $(inputs.ADES_STAGEOUT_AWS_REGION)
                #AWS__AuthenticationRegion: $(inputs.ADES_STAGEOUT_AWS_REGION)
                # uncomment if you need profiles
                # AWS__Profile: $(inputs.ADES_STAGEOUT_AWS_PROFILE)
                # AWS__ProfilesLocation: $(inputs.aws_profiles_location.path)
            ResourceRequirement: {}
      rulez:
        cwl: ""      
      
      pod:
        env: {}

      # custom backoff limit for calrissian job
      backofflimit: 3
      
        
    wps:
      pepBaseUrl: "http://ades-pep:5576"
      usePep: "true"
      maincfgtpl: "files/main.cfg.tpl"
    persistence:
      enabled: true
      # existingUserDataClaim:
      # existingProcServicesClaim:
      storageClass: "managed-nfs-storage"
      userDataAccessMode: ReadWriteOnce
      userDataSize: 10Gi
      procServicesAccessMode: ReadWriteOnce
      procServicesSize: 5Gi
    # values - end
  # timeout: 25m0s
  interval: 1m0s
