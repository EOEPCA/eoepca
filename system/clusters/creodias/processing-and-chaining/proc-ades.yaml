apiVersion: helm.toolkit.fluxcd.io/v2beta1
kind: HelmRelease
metadata:
  name: proc-ades
  namespace: proc
spec:
  chart:
    spec:
      chart: ades
      version: 0.9.10
      sourceRef:
        kind: HelmRepository
        name: eoepca
        namespace: common
  values:
    # values - start
    replicaCount: 1
    image:
      pullPolicy: Always
      # Overrides the image tag whose default is the chart appVersion.
      tag: "0.9.7"
    nameOverride: ""
    fullnameOverride: ""
    serviceAccount:
      # Specifies whether a service account should be created
      create: true
      # Annotations to add to the service account
      annotations: {}
      # The name of the service account to use.
      # If not set and create is true, a name is generated using the fullname template
      name: ""
    podAnnotations: {}
    podSecurityContext:
      {}
      # fsGroup: 2000
    securityContext:
      {}
      # capabilities:
      #   drop:
      #   - ALL
      # readOnlyRootFilesystem: true
      # runAsNonRoot: true
      # runAsUser: 1000
    service:
      type: ClusterIP
      port: 80
    ingress:
      enabled: true
      annotations: {}
      hosts:
        - host: ades-open.demo.eoepca.org
          paths: ["/"]
      tls: []
      #  - secretName: chart-example-tls
      #    hosts:
      #      - chart-example.local
    resources:
      # We usually recommend not to specify default resources and to leave this as a conscious
      # choice for the user. This also increases chances charts run on environments with little
      # resources, such as Minikube. If you do want to specify resources, uncomment the following
      # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
      limits:
        cpu: 2
        memory: 4Gi
      requests:
        cpu: 500m
        memory: 2Gi
    autoscaling:
      enabled: false
      minReplicas: 1
      maxReplicas: 3
      targetCPUUtilizationPercentage: 80
      # targetMemoryUtilizationPercentage: 80
    storageClassName: managed-nfs-storage
    clusterAdminRoleName: cluster-admin
    nodeSelector: {}
    tolerations: []
    affinity: {}
    useKubeProxy: True
    workflowExecutor:
      # Necessary if useKubeProxy set to false
      # kubeconfig: "files/kubeconfig"

      # Here specify fixed inputs to all workflows execution in all stages (main, stage-in/out)
      # They will be prefixed with 'ADES_'. e.g. 'APP: ades' will be 'ADES_APP: ades'
      inputs:
        APP: ades

        STAGEIN_AWS_SERVICEURL: http://data.cloudferro.com
        STAGEIN_AWS_ACCESS_KEY_ID: test
        STAGEIN_AWS_SECRET_ACCESS_KEY: test

        STAGEOUT_AWS_SERVICEURL: https://cf2.cloudferro.com:8080
      #  STAGEOUT_AWS_ACCESS_KEY_ID: 4ceda7292edc4cc997d133079b469900
      #  STAGEOUT_AWS_SECRET_ACCESS_KEY: 7d824cbfc90147318fa6ac7fe0e9a174
      #  STAGEOUT_AWS_REGION: RegionOne
      #  STAGEOUT_OUTPUT: s3://processing_results

      #    STAGEOUT_STORAGE_HOST: https://nx13206.your-storageshare.de/
      #    STAGEOUT_STORAGE_USERNAME: eoepca-storagecd 
      #    STAGEOUT_STORAGE_APIKEY: 4k8wMajA5ABaYdk

      useResourceManager: "true"
      resourceManagerWorkspacePrefix: "demo-user"
      resourceManagerEndpoint: "https://workspace-api.test.demo.eoepca.org"
      platformDomain: "https://test.demo.eoepca.org"

      main:
        cwl: ""

      stagein:
        cwl: |
          cwlVersion: v1.0
          baseCommand: Stars
          doc: "Run Stars for staging input data"
          class: CommandLineTool
          hints:
            DockerRequirement:
              dockerPull: terradue/stars:1.0.0-beta.7
          id: stars
          arguments:
          - copy
          - -v
          - -rel
          - -r
          - '4'
          - -o
          - ./
          - --harvest
          inputs: 
            ADES_STAGEIN_AWS_SERVICEURL: 
              type: string?
            ADES_STAGEIN_AWS_ACCESS_KEY_ID:
              type: string?
            ADES_STAGEIN_AWS_SECRET_ACCESS_KEY:
              type: string?
          outputs: {}
          requirements:
            EnvVarRequirement:
              envDef:
                PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
                # AWS__Profile: $(inputs.aws_profile)
                # AWS__ProfilesLocation: $(inputs.aws_profiles_location.path)
                AWS__ServiceURL: $(inputs.ADES_STAGEIN_AWS_SERVICEURL)
                AWS_ACCESS_KEY_ID: $(inputs.ADES_STAGEIN_AWS_ACCESS_KEY_ID)
                AWS_SECRET_ACCESS_KEY: $(inputs.ADES_STAGEIN_AWS_SECRET_ACCESS_KEY)
            ResourceRequirement: {}
      stageout:
        cwl: |
          cwlVersion: v1.0
          baseCommand: Stars
          doc: "Run Stars for staging results"
          class: CommandLineTool
          hints:
            DockerRequirement:
              dockerPull: terradue/stars:1.0.0-beta.7
          id: stars
          arguments:
          - copy
          - -v
          - -r
          - '4'
          inputs: 
            ADES_STAGEOUT_AWS_PROFILE:
              type: string?
            ADES_STAGEOUT_AWS_SERVICEURL: 
              type: string?
            ADES_STAGEOUT_AWS_ACCESS_KEY_ID: 
              type: string?
            ADES_STAGEOUT_AWS_SECRET_ACCESS_KEY: 
              type: string?
            aws_profiles_location:
              type: File?
            result_directory:
              type: Directory?
              inputBinding:
                position: 7
            ADES_STAGEOUT_OUTPUT:
              type: string?
              inputBinding:
                position: 5
                prefix: -o
                valueFrom: $( self + "/" + inputs.process )
            ADES_STAGEOUT_AWS_REGION:
              type: string?
            process:
              type: string?
              inputBinding:
                position: 6
                prefix: -res
                valueFrom: $( inputs.process + ".res" )
          outputs: {}
          requirements:
            InlineJavascriptRequirement: {}
            EnvVarRequirement:
              envDef:
                PATH: /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
                AWS__ServiceURL: $(inputs.ADES_STAGEOUT_AWS_SERVICEURL)
                AWS_ACCESS_KEY_ID: $(inputs.ADES_STAGEOUT_AWS_ACCESS_KEY_ID)
                AWS_SECRET_ACCESS_KEY: $(inputs.ADES_STAGEOUT_AWS_SECRET_ACCESS_KEY)
                AWS__SignatureVersion: "2"
            ResourceRequirement: {}
      rulez:
        cwl: ""

      pod_env_vars:
        yaml: "{}"


      # kubernetes storage class to be used for provisioning volumes. Must be a persistent volume claim compliant (glusterfs-storage)
      processingStorageClass: managed-nfs-storage
      # Size of the Kubernetes Tmp Volumes
      processingVolumeTmpSize: "6Gi"
      # Size of the Kubernetes Output Volumes
      processingVolumeOutputSize: "6Gi"
      # Max ram to use for a job
      processingMaxRam: "8Gi"
      # Max number of CPU cores to use concurrently for a job
      processingMaxCores: "4"
      # if false the Ades will clean the volume after the workflow has successfully finished running
      processingKeepWorkspace: "False"
      # image pull secrects
      imagePullSecrets: []
      #  custom stagein cwl
      #stageincwl: "files/stageincwl.cwl"
      #maincwl: "files/maincwlmetrics.cwl"
      
      pod:
        env: {}

      # custom backoff limit for calrissian job
      backofflimit: 3
      
        
    wps:
      pepBaseUrl: "http://proc-ades-pep:5576"
      usePep: "true"
      maincfgtpl: "files/main.cfg.tpl"
    persistence:
      enabled: true
      # existingUserDataClaim:
      # existingProcServicesClaim:
      storageClass: "managed-nfs-storage"
      userDataAccessMode: ReadWriteOnce
      userDataSize: 10Gi
      procServicesAccessMode: ReadWriteOnce
      procServicesSize: 5Gi
    # values - end
  # timeout: 25m0s
  interval: 1m0s
